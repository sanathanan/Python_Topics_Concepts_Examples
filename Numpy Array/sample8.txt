import os
import tempfile
import subprocess
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# === CONFIG ===
llm = ChatOpenAI(temperature=0, model_name="gpt-4", openai_api_key=os.getenv("OPENAI_API_KEY"))

JUNIT_JAR = os.path.abspath("lib/junit-4.13.2.jar")
HAMCREST_JAR = os.path.abspath("lib/hamcrest-core-1.3.jar")
IS_WINDOWS = os.name == "nt"

# === AGENTS ===
class TestCaseParserAgent:
    @staticmethod
    def parse(raw_text):
        prompt = f"""
        Extract structured test cases from the following document.

        Return as a list of dictionaries with these keys:
        - id
        - type
        - name
        - description
        - precondition
        - steps (list)
        - expected (list)
        - test_data (list)

        Input:
        {raw_text}
        """
        response = llm([HumanMessage(content=prompt)])
        return eval(response.content)

class CodeGeneratorAgent:
    @staticmethod
    def generate(test_case, language="python"):
        if language == "java":
            prompt = f"""
            Write a Java JUnit test case for the following:

            ID: {test_case['id']}
            Name: {test_case['name']}
            Description: {test_case['description']}
            Precondition: {test_case['precondition']}
            Steps:
            {'\\n'.join(test_case['steps'])}
            Expected:
            {'\\n'.join(test_case['expected'])}
            Test Data:
            {'\\n'.join(test_case['test_data'])}

            Include necessary imports and class/method structure.
            """
        else:
            prompt = f"""
            Write a Python pytest function for the following:

            ID: {test_case['id']}
            Name: {test_case['name']}
            Description: {test_case['description']}
            Precondition: {test_case['precondition']}
            Steps:
            {'\\n'.join(test_case['steps'])}
            Expected:
            {'\\n'.join(test_case['expected'])}
            Test Data:
            {'\\n'.join(test_case['test_data'])}

            Use requests for API or pseudocode if UI.
            """
        response = llm([HumanMessage(content=prompt)])
        return response.content

class CodeExecutorAgent:
    @staticmethod
    def execute(code_str, language="python"):
        with tempfile.TemporaryDirectory() as tmpdir:
            if language == "python":
                test_file = os.path.join(tmpdir, "test_case.py")
                with open(test_file, "w") as f:
                    f.write(code_str)
                result = subprocess.run(["pytest", test_file, "-v", "--tb=short"], capture_output=True, text=True)
                return result.stdout
            elif language == "java":
                java_file = os.path.join(tmpdir, "TestCase.java")
                with open(java_file, "w") as f:
                    f.write(code_str)
                compile_result = subprocess.run(["javac", java_file], capture_output=True, text=True)
                if compile_result.returncode != 0:
                    return f"Compilation Failed:\n{compile_result.stderr}"
                classpath = f"{tmpdir}{';' if IS_WINDOWS else ':'}{JUNIT_JAR}{';' if IS_WINDOWS else ':'}{HAMCREST_JAR}"
                test_result = subprocess.run(["java", "-cp", classpath, "org.junit.runner.JUnitCore", "TestCase"],
                                             capture_output=True, text=True)
                return test_result.stdout + test_result.stderr

class FeedbackAgent:
    @staticmethod
    def analyze(test_case, code_str, test_result):
        prompt = f"""
        Analyze the test result and suggest improvements or fixes.

        Test Case: {test_case['id']} - {test_case['name']}
        Code:
        {code_str}

        Result:
        {test_result}
        """
        response = llm([HumanMessage(content=prompt)])
        return response.content

# === MAIN RUNNER ===
class AgenticTestRunner:
    @staticmethod
    def run_all(raw_text):
        test_cases = TestCaseParserAgent.parse(raw_text)
        used_filenames = {}

        for language in ["python", "java"]:
            base_dir = os.path.join("agentic_outputs", language)
            code_dir = os.path.join(base_dir, "test_cases")
            result_dir = os.path.join(base_dir, "execution_results")
            feedback_dir = os.path.join(base_dir, "llm_feedback")
            os.makedirs(code_dir, exist_ok=True)
            os.makedirs(result_dir, exist_ok=True)
            os.makedirs(feedback_dir, exist_ok=True)

            for i, tc in enumerate(test_cases):
                # Unique base filename
                key = f"{tc['id']}_{tc['name'].replace(' ', '_')}"
                used_filenames[key] = used_filenames.get(key, 0) + 1
                base_filename = f"{key}_{used_filenames[key]}"
                ext = "py" if language == "python" else "java"

                # Generate code
                code = CodeGeneratorAgent.generate(tc, language)
                code_path = os.path.join(code_dir, f"{base_filename}_code.{ext}")
                with open(code_path, "w") as f:
                    f.write(code)

                # Execute and save result
                result = CodeExecutorAgent.execute(code, language)
                result_path = os.path.join(result_dir, f"{base_filename}_result.txt")
                with open(result_path, "w") as f:
                    f.write(result)

                # Feedback
                feedback = FeedbackAgent.analyze(tc, code, result)
                feedback_path = os.path.join(feedback_dir, f"{base_filename}_feedback.txt")
                with open(feedback_path, "w") as f:
                    f.write(feedback)

        print("\nâœ… All outputs saved under './agentic_outputs/' for both Python and Java.")

# === ENTRY POINT ===
if __name__ == "__main__":
    input_path = os.path.join("output_folder", "User_Stories_Test_Cases.txt")
    with open(input_path, "r") as file:
        raw_test_cases = file.read()
    AgenticTestRunner.run_all(raw_test_cases)
